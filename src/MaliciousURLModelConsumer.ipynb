{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05363ff8-ee11-44e4-9547-93e575345e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from river import datasets\n",
    "from river import metrics\n",
    "from river import tree\n",
    "from river import ensemble\n",
    "from river import evaluate\n",
    "from river import compose\n",
    "from river import naive_bayes\n",
    "from river import anomaly\n",
    "from river import compose\n",
    "from river import datasets\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "from confluent_kafka import Producer,Consumer,TopicPartition\n",
    "import certifi\n",
    "import time\n",
    "import json\n",
    "import pandas\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93333d02-5133-43a6-8ef2-17d25f3f0b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c06d881-59ee-432a-a205-72d7f4c064e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user= os.environ['kafka_username']\n",
    "password= os.environ['kafka_password']\n",
    "bsts= os.environ['kafka_bootstrap_servers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84d1129-5f3e-4c31-b93b-4e7901c8195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def consume_messages(group_id,model_artifact,max_messages,feature_topic,partitions):    \n",
    "    features_consumer_conf = {'bootstrap.servers': bsts,\n",
    "                          'sasl.username': user,\n",
    "                          'sasl.password': password,\n",
    "                          'sasl.mechanism': 'PLAIN',\n",
    "                          'security.protocol': 'SASL_SSL',\n",
    "                          'ssl.ca.location': certifi.where(),\n",
    "                          'group.id': group_id,\n",
    "                          'enable.auto.commit': True,\n",
    "                          'auto.commit.interval.ms':1000,         \n",
    "                          'auto.offset.reset': 'latest'}\n",
    "    features_consumer = Consumer(features_consumer_conf)  \n",
    "    \n",
    "    print(f'\\nNow subscribing to features topic:{feature_topic}')\n",
    "        \n",
    "    #features_consumer.subscribe([feature_topic])\n",
    "    tps = []\n",
    "    for p in range(partitions):\n",
    "        tps.append(TopicPartition(feature_topic,p))\n",
    "    \n",
    "    features_consumer.assign(tps)\n",
    "    \n",
    "    cnt = 0\n",
    "    ignored=0\n",
    "    msg = None\n",
    "    error_cnt = 0\n",
    "    end_learn_ts = 0\n",
    "    st_learn_ts = 0\n",
    "\n",
    "    st_processing_time = 0\n",
    "    \n",
    "    learning_durations=[]\n",
    "    prediction_durations=[]\n",
    "    processing_durations = []\n",
    "    score_and_truth = []\n",
    "    mem_usage = []\n",
    "    end_to_end_processing_durations = []\n",
    "    messaging_latencies = []\n",
    "    while(True):           \n",
    "        if(cnt>0 and cnt%max_messages==0):\n",
    "            break;\n",
    "        messages = features_consumer.consume(num_messages=1000,timeout=0.1)    \n",
    "        if len(messages)==0: continue\n",
    "        \n",
    "        for msg in messages:\n",
    "            if msg is None: continue\n",
    "            if msg.error():\n",
    "                error_cnt = error_cnt + 1\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:                    \n",
    "                        if(error_cnt%1000==0):\n",
    "                            print('error')\n",
    "                            print(msg)\n",
    "                        sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\n",
    "                                                 (msg.topic(), msg.partition(), msg.offset()))\n",
    "            else:       \n",
    "                try:         \n",
    "                    msg_arrival_time = time.time()\n",
    "                    message = json.loads(msg.value().decode(\"utf-8\"))            \n",
    "                    cnt = cnt + 1\n",
    "\n",
    "                    f = message['f']\n",
    "                    y = (message['y']=='true')              \n",
    "                    msg_produce_ts = message['st']\n",
    "                    messaging_latencies.append(msg_arrival_time-msg_produce_ts)\n",
    "                    if(cnt==1):\n",
    "                        st_processing_time = time.time()\n",
    "\n",
    "                    st_learn_ts = time.time()\n",
    "                    model_artifact = model_artifact.learn_one(f,y)      \n",
    "                    end_learn_ts = time.time()\n",
    "                    learning_durations.append(end_learn_ts-st_learn_ts)            \n",
    "                        \n",
    "                    st_prediction_time = time.time()            \n",
    "                    score = model_artifact.predict_one(f)\n",
    "                    score_and_truth.append({'y':y,'score':score})\n",
    "                    end_prediction_time = time.time()  \n",
    "                    prediction_durations.append(end_prediction_time-st_prediction_time)\n",
    "\n",
    "\n",
    "                    msg_departure_time = time.time()\n",
    "                    processing_durations.append(msg_departure_time-msg_arrival_time)\n",
    "                    end_to_end_processing_durations.append(msg_departure_time-msg_produce_ts)\n",
    "                    if(cnt%1000==0):\n",
    "                        print(f'Processed {cnt}')\n",
    "                        mem_usage.append(model_artifact._raw_memory_usage)\n",
    "                    if(cnt%max_messages==0):\n",
    "                        break;\n",
    "                except Exception as  e:      \n",
    "                    if(cnt%max_messages==0):\n",
    "                        break;\n",
    "                    #print(json.loads(msg.value().decode(\"utf-8\")))\n",
    "                    #print(e, file=sys.stdout)\n",
    "                    ignored = ignored + 1\n",
    "                    if(ignored%100==0):\n",
    "                        print(e, file=sys.stdout)\n",
    "                        print(f'ignored ={ignored} total = {cnt}')\n",
    "\n",
    "    total_time = time.time() - st_processing_time\n",
    "    features_consumer.commit()\n",
    "    features_consumer.close() \n",
    "    \n",
    "    print(f'Closing Consumer - Total time take in seconds {total_time}')\n",
    "    return score_and_truth,messaging_latencies,processing_durations,end_to_end_processing_durations, prediction_durations, learning_durations,mem_usage,total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30613b73-7440-4d2d-bfdf-792563642547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from river import metrics\n",
    "\n",
    "def get_record(type_of_duration,durations):\n",
    "  \n",
    "   return {'Type of durations' :type_of_duration,\n",
    "        'MEAN':statistics.mean(durations)*1000,\n",
    "        'MEDIAN':statistics.median(durations)*1000,\n",
    "        'MAXIMUM':max(durations)*1000,\n",
    "        'MINIMUM':min(durations)*1000\n",
    "        }\n",
    "    \n",
    "def get_results(score_and_truth,messaging_latencies,processing_durations,end_to_end_processing_durations, prediction_durations, learning_durations,mem_usage,total_time):\n",
    "    auc = metrics.ROCAUC()\n",
    "    f1 = metrics.F1()\n",
    "    recall = metrics.MicroRecall()\n",
    "    for m in score_and_truth:\n",
    "        y = m['y']\n",
    "        score = m['score']\n",
    "        auc = auc.update(y,score)\n",
    "        f1 = f1.update(y, score)\n",
    "        recall = recall.update(y, score)\n",
    "    \n",
    "  \n",
    "    total_records = len(score_and_truth)\n",
    "    \n",
    "    avg_memory_usage = None\n",
    "    if len(mem_usage)>0:     \n",
    "        avg_memory_usage = statistics.mean(mem_usage)\n",
    "    print(f'Messages consumed:{total_records},Total Cumulative Time (seconds): {total_time}')    \n",
    "    print(f'{auc}')\n",
    "    print(f'{f1}')\n",
    "    print(f'{recall}')\n",
    "    print(f'AVERAGE MEMORY USAGE {avg_memory_usage}')\n",
    "    \n",
    "    d=[]\n",
    " \n",
    "   \n",
    "    d.append(get_record('MESSAGING LATENCY(ms)',messaging_latencies))\n",
    "    d.append(get_record('PROCESSING DURATIONS ON ARRIVAL(ms)',processing_durations))\n",
    "    d.append(get_record('    PREDICTION DURATIONS ON ARRIVAL(ms)',prediction_durations))\n",
    "    d.append(get_record('    LEARNING DURATIONS ON ARRIVAL(ms)',learning_durations))\n",
    "    d.append(get_record('END TO END DURATIONS(ms)',end_to_end_processing_durations))\n",
    "                          \n",
    "    df = pandas.DataFrame(data=d)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6444fa65-9fe2-4c14-9134-0974a3c3e1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now subscribing to features topic:features\n",
      "Processed 1000\n",
      "Processed 2000\n",
      "Processed 3000\n",
      "Processed 4000\n",
      "Processed 5000\n",
      "Closing Consumer - Total time take in seconds 7.986349582672119\n"
     ]
    }
   ],
   "source": [
    "model_artifact = ensemble.AdaptiveRandomForestClassifier(leaf_prediction=\"mc\")\n",
    "group_id = 'ADRF_1'\n",
    "max_messages = 5000\n",
    "feature_topic = 'features'\n",
    "no_of_partitions=8\n",
    "\n",
    "score_and_truth,messaging_latencies,processing_durations, end_to_end_processing_durations,prediction_durations, learning_durations,mem_usage,total_time = consume_messages(group_id,model_artifact,max_messages,feature_topic,no_of_partitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50259b8f-4e9c-4199-9dac-3f31cc357bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages consumed:5000,Total Cumulative Time (seconds): 7.986349582672119\n",
      "ROCAUC: 85.74%\n",
      "F1: 84.15%\n",
      "MicroRecall: 85.74%\n",
      "AVERAGE MEMORY USAGE 5508067.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of durations</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>MEDIAN</th>\n",
       "      <th>MAXIMUM</th>\n",
       "      <th>MINIMUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESSAGING LATENCY(ms)</td>\n",
       "      <td>966.885068</td>\n",
       "      <td>965.795755</td>\n",
       "      <td>1933.725834</td>\n",
       "      <td>195.620060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROCESSING DURATIONS ON ARRIVAL(ms)</td>\n",
       "      <td>1.151372</td>\n",
       "      <td>1.102567</td>\n",
       "      <td>42.501926</td>\n",
       "      <td>0.404119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PREDICTION DURATIONS ON ARRIVAL(ms)</td>\n",
       "      <td>0.145159</td>\n",
       "      <td>0.136137</td>\n",
       "      <td>0.359535</td>\n",
       "      <td>0.078201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LEARNING DURATIONS ON ARRIVAL(ms)</td>\n",
       "      <td>0.966984</td>\n",
       "      <td>0.921011</td>\n",
       "      <td>42.295933</td>\n",
       "      <td>0.269413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>END TO END DURATIONS(ms)</td>\n",
       "      <td>968.036440</td>\n",
       "      <td>967.025518</td>\n",
       "      <td>1934.567690</td>\n",
       "      <td>196.900368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Type of durations        MEAN      MEDIAN      MAXIMUM  \\\n",
       "0                MESSAGING LATENCY(ms)  966.885068  965.795755  1933.725834   \n",
       "1  PROCESSING DURATIONS ON ARRIVAL(ms)    1.151372    1.102567    42.501926   \n",
       "2  PREDICTION DURATIONS ON ARRIVAL(ms)    0.145159    0.136137     0.359535   \n",
       "3    LEARNING DURATIONS ON ARRIVAL(ms)    0.966984    0.921011    42.295933   \n",
       "4             END TO END DURATIONS(ms)  968.036440  967.025518  1934.567690   \n",
       "\n",
       "      MINIMUM  \n",
       "0  195.620060  \n",
       "1    0.404119  \n",
       "2    0.078201  \n",
       "3    0.269413  \n",
       "4  196.900368  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_results(score_and_truth,messaging_latencies,processing_durations, end_to_end_processing_durations,prediction_durations, learning_durations,mem_usage,total_time)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b747e2b-4839-4acb-bc93-da1df19f2b2c",
   "metadata": {},
   "source": [
    "## Types of Durations\n",
    "\n",
    "Note how the messaging latency accounts for most of the latency. A faster and more expensive cluster will improve throughput proportionately (We process 800 records per second for the model ensemble.AdaptiveRandomForestClassifier(leaf_prediction=\"mc\")\n",
    "\n",
    "|    | Type of durations                   |       MEAN |     MEDIAN |     MAXIMUM |     MINIMUM |\n",
    "|---:|:------------------------------------|-----------:|-----------:|------------:|------------:|\n",
    "|  0 | MESSAGING LATENCY(ms)               | 972.558    | 956.883    | 1663.33     | 390.412     |\n",
    "|  1 | PROCESSING DURATIONS ON ARRIVAL(ms) |   1.34578  |   1.28746  |   42.8333   |   0.345469  |\n",
    "|  2 | PREDICTION DURATIONS ON ARRIVAL(ms) |   0.175217 |   0.167131 |    0.539541 |   0.0786781 |\n",
    "|  3 | LEARNING DURATIONS ON ARRIVAL(ms)   |   1.13075  |   1.07217  |   42.6424   |   0.233173  |\n",
    "|  4 | END TO END DURATIONS(ms)            | 973.903    | 958.406    | 1665.24     | 391.795     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29167097-33b1-4fd3-9be5-4edd90a90eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.Series(messaging_latencies).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c0a2d-7943-46b6-94d6-3d0466da60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.Series(processing_durations).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96af7fa-20da-4320-adb8-33b57f613e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.Series(end_to_end_processing_durations).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
