{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05363ff8-ee11-44e4-9547-93e575345e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from river import datasets\n",
    "from river import metrics\n",
    "from river import tree\n",
    "from river import ensemble\n",
    "from river import evaluate\n",
    "from river import compose\n",
    "from river import naive_bayes\n",
    "from river import anomaly\n",
    "from river import compose\n",
    "from river import datasets\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "from confluent_kafka import Producer,Consumer\n",
    "import certifi\n",
    "import time\n",
    "import json\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e75d7bf0-296f-42f8-8848-f9f438284085",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=[]\n",
    "classifier='HoeffdingAdaptiveTreeClassifier'\n",
    "classifiers.append(classifier)\n",
    "classifier='SRPClassifierHAT'\n",
    "classifiers.append(classifier)\n",
    "classifier='SRPClassifierNaiveBayes'\n",
    "classifiers.append(classifier)\n",
    "classifier='AdaptiveRandomForestClassifier'\n",
    "classifiers.append(classifier)\n",
    "#classifier='HalfSpaceTrees'\n",
    "#classifiers.append(classifier)\n",
    "model_artifact = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99e5efa-2589-43d1-ab3f-ddfcde4b4925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.sysnet.ucsd.edu/projects/url/url_svmlight.tar.gz (233.66 MB)\n",
      "Uncompressing into /home/ubuntu/river_data/MaliciousURL\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'avg_ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 33\u001b[0m\n\u001b[1;32m     28\u001b[0m total_duration \u001b[38;5;241m=\u001b[39m training_end_ts\u001b[38;5;241m-\u001b[39mtraining_st_ts\n\u001b[1;32m     29\u001b[0m avg_duration \u001b[38;5;241m=\u001b[39m (total_duration\u001b[38;5;241m/\u001b[39mmax_size)     \n\u001b[1;32m     30\u001b[0m d_train\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m:classifier,\n\u001b[1;32m     31\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Model Training Time(ms)\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_duration \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     32\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected Train Time 1 million records (s)\u001b[39m\u001b[38;5;124m'\u001b[39m:avg_duration \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000000\u001b[39m,\n\u001b[0;32m---> 33\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected time 1 million (mins)\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mavg_ts\u001b[49m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1000000\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m),\n\u001b[1;32m     34\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Training Throughput (sub-second-response) \u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mavg_duration)})\n\u001b[1;32m     36\u001b[0m prediction_st_ts \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f, y \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'avg_ts' is not defined"
     ]
    }
   ],
   "source": [
    "max_size=1000\n",
    "dataset = datasets.MaliciousURL()\n",
    "d_train=[]\n",
    "d_predict=[]\n",
    "d_total=[]\n",
    "for classifier in classifiers:\n",
    "    data = dataset.take(max_size)\n",
    "    if classifier=='HoeffdingAdaptiveTreeClassifier':\n",
    "            model_artifact = tree.HoeffdingAdaptiveTreeClassifier(grace_period=100,  delta=1e-5, leaf_prediction='nb', nb_threshold=10,seed=0)\n",
    "    elif classifier=='SRPClassifierHAT':\n",
    "            model_artifact =  ensemble.SRPClassifier(\n",
    "                                                   model=tree.HoeffdingAdaptiveTreeClassifier(grace_period=100,  delta=1e-5, leaf_prediction='nb', nb_threshold=10, seed=0), seed=42,\n",
    "                                                )\n",
    "    elif classifier=='SRPClassifierNaiveBayes':\n",
    "            model_artifact = ensemble.SRPClassifier(\n",
    "                                                 model=naive_bayes.BernoulliNB(alpha=1), seed=42,\n",
    "                                              )\n",
    "    elif classifier=='AdaptiveRandomForestClassifier':\n",
    "            model_artifact = ensemble.AdaptiveRandomForestClassifier(leaf_prediction=\"mc\")\n",
    "\n",
    "#    elif classifier=='HalfSpaceTrees':\n",
    "#            model_artifact = compose.Pipeline(preprocessing.MinMaxScaler(),anomaly.HalfSpaceTrees(seed=42))\n",
    "    print(model_artifact)\n",
    "    cnt = 0\n",
    "    training_st_ts = time.time()\n",
    "    for f, y in data:\n",
    "        cnt = cnt + 1\n",
    "        model_artifact = model_artifact.learn_one(f,y)\n",
    "    training_end_ts = time.time()\n",
    "    total_training_duration = training_end_ts-training_st_ts\n",
    "    avg_duration = (total_training_duration/max_size)     \n",
    "    d_train.append({'Classifier':classifier,\n",
    "              'Expected Time(ms) Per Record': avg_duration * 1000,\n",
    "              'Expected Time Million Records (s)':avg_duration * 1000000,\n",
    "              'Expected Time Million Records (mins)': avg_duration * (1000000/60),\n",
    "              'Max Prediction Throughput (sub-second-response) ': round(1/avg_duration)})\n",
    "    \n",
    "    data = dataset.take(max_size)\n",
    "    prediction_st_ts = time.time()\n",
    "    for f, y in data:\n",
    "        cnt = cnt + 1\n",
    "        if classifier=='HalfSpaceTrees':\n",
    "            model_artifact.learn_one(f)\n",
    "        else:\n",
    "            model_artifact.predict_one(f)\n",
    "    prediction_end_ts = time.time()\n",
    "    total_prediction_duration = prediction_end_ts-prediction_st_ts\n",
    "    avg_duration = (total_prediction_duration/max_size)     \n",
    "    d_predict.append({'Classifier':classifier,\n",
    "              'Expected Time(ms) Per Record': avg_duration * 1000,\n",
    "              'Expected Time Million Records (s)':avg_duration * 1000000,\n",
    "              'Expected Time Million Records (mins)': avg_duration * (1000000/60),\n",
    "              'Max Prediction Throughput (sub-second-response) ': round(1/avg_duration)})\n",
    "\n",
    "    total_duration = total_training_duration + total_prediction_duration\n",
    "    avg_duration = (total_duration/max_size)     \n",
    "    d_total.append({'Classifier':classifier,\n",
    "              'Expected Time(ms) Per Record': avg_duration * 1000,\n",
    "              'Expected Time Million Records (s)':avg_duration * 1000000,\n",
    "              'Expected Time Million Records (mins)': avg_duration * (1000000/60),\n",
    "              'Max Prediction Throughput (sub-second-response) ': round(1/avg_duration)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8650b9-8a9b-44f5-8e9a-86c14034f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training')\n",
    "df_train = pandas.DataFrame(data=d_train)\n",
    "display(df_train)\n",
    "\n",
    "print('Prediction')\n",
    "df_predict = pandas.DataFrame(data=d_predict)\n",
    "display(df_predict)\n",
    "\n",
    "print('Total')\n",
    "df_total = pandas.DataFrame(data=d_total)\n",
    "display(df_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c51b66-e470-41c5-8443-7b24107ddcc7",
   "metadata": {},
   "source": [
    "## Results for Maximum Sustainable Throughtput Calculations \n",
    "Maximum sustainable throughput is the number of records we can train/predict in a single thread in 1 second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d3ae1-06e6-47f4-94ba-e1c482307a14",
   "metadata": {},
   "source": [
    "|    | Classifier                      |   Avg Model Training Time(ms) |   Expected Train Time 1 million records (s) |   Expected time 1 million (mins) |   Max Training Throughput (sub-second-response)  |\n",
    "|---:|:--------------------------------|------------------------------:|--------------------------------------------:|---------------------------------:|-------------------------------------------------:|\n",
    "|  0 | HoeffdingAdaptiveTreeClassifier |                      1.81765  |                                    1817.65  |                        0.0119209 |                                              550 |\n",
    "|  1 | SRPClassifierHAT                |                     28.3744   |                                   28374.4   |                        0.0119209 |                                               35 |\n",
    "|  2 | SRPClassifierNaiveBayes         |                      4.33598  |                                    4335.98  |                        0.0119209 |                                              231 |\n",
    "|  3 | AdaptiveRandomForestClassifier  |                      1.02246  |                                    1022.46  |                        0.0119209 |                                              978 |\n",
    "|  4 | HalfSpaceTrees                  |                      0.221211 |                                     221.211 |                        0.0119209 |                                             4521 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33659d74-3a9e-4e38-87cb-703d8809da25",
   "metadata": {},
   "source": [
    "|    | Classifier                      |   Avg Model Prediction Time(ms) |   Expected Prediction Time 1 million records (s) |   Expected time 1 million (mins) |   Max Prediction Throughput (sub-second-response)  |\n",
    "|---:|:--------------------------------|--------------------------------:|-------------------------------------------------:|---------------------------------:|---------------------------------------------------:|\n",
    "|  0 | HoeffdingAdaptiveTreeClassifier |                     2.38419e-07 |                                      0.000238419 |                        0.0119209 |                                         4194304000 |\n",
    "|  1 | SRPClassifierHAT                |                     7.15256e-07 |                                      0.000715256 |                        0.0119209 |                                         1398101333 |\n",
    "|  2 | SRPClassifierNaiveBayes         |                     2.38419e-07 |                                      0.000238419 |                        0.0119209 |                                         4194304000 |\\n|  3 | AdaptiveRandomForestClassifier  |                     2.38419e-07 |                                      0.000238419 |                        0.0119209 |                                         4194304000 |\n",
    "|  4 | HalfSpaceTrees                  |                     4.76837e-07 |                                      0.000476837 |                        0.0119209 |                                         2097152000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96e9da-01f6-457b-a7e8-339fac1be802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
