{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e38a0b2-13d7-4ee0-b56c-537e5ea77851",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from river import datasets\n",
    "from river import metrics\n",
    "from river import tree\n",
    "from river import ensemble\n",
    "from river import evaluate\n",
    "from river import compose\n",
    "from river import naive_bayes\n",
    "from river import anomaly\n",
    "from river import compose\n",
    "from river import datasets\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "from confluent_kafka import Producer,Consumer\n",
    "import certifi\n",
    "import time\n",
    "import json\n",
    "import pandas\n",
    "import mlflow\n",
    "import codecs\n",
    "import pickle\n",
    "import sys\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0df5f-1892-4891-bfec-76f764958a0a",
   "metadata": {},
   "source": [
    "## Prepare to publish models to the Model Update Topic\n",
    "\n",
    "All model updates are directly pushed to the topic `model_updates` as a serialized pickle file content which is base64 encoded.\n",
    "\n",
    "This is not the ideal mecahnism to publish model updates. We would typically only publish the `model_name` and `model_version` because\n",
    "Kafka topics are not designed to handle more than 8MB of payload. However to keep this demo simplified we are publishing our model updates directly to the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c014e38-54bf-4a01-a8af-ba9d08a44f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user= os.environ['KAFKA_USER_NAME']\n",
    "password= os.environ['KAFKA_PASSWORD']\n",
    "bsts= os.environ['KAFKA_BOOTSTRAP_SERVERS']\n",
    "topic = 'model_updates'\n",
    "conf = {'bootstrap.servers': bsts,\n",
    "            'sasl.mechanism': 'PLAIN',\n",
    "            'security.protocol': 'SASL_SSL',\n",
    "            'ssl.ca.location': certifi.where(),\n",
    "            'sasl.username': user,\n",
    "            'sasl.password': password,            \n",
    "            'message.max.bytes': 8000000,\n",
    "            'linger.ms': 100,\n",
    "            'client.id': 'model-icde-2023'}\n",
    "producer = Producer(conf) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb8c877-7d2d-44ff-8d68-a1c29873a6dc",
   "metadata": {},
   "source": [
    "`get_model_artifact(run_id)` - Download the model artifacts (pickle file in our case) based on the experiment run_id and save it a local file path `models/model.pkl`. Again note that is a simplified example\n",
    "\n",
    "`publish_model_update_to_model_endpoint` - Publish the model pickle file contents as a base64 encoded to the topic `model_updates` along with the `model_version` which is obtained from the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e097d6e9-9261-42c2-ba6f-e163cee6e68e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_model_artifact(run_id):\n",
    "    local_path = client.download_artifacts(run_id, \"models/model.pkl\", '/tmp/')\n",
    "    with open(local_path, 'rb') as f:\n",
    "        m_a = pickle.load(f)\n",
    "        return m_a\n",
    "\n",
    "def publish_model_update_to_model_endpoint(run_id,model_version):\n",
    "    m_a = get_model_artifact(run_id)\n",
    "\n",
    "    pkd = pickle.dumps(m_a)\n",
    "    pickled = codecs.encode(pkd, \"base64\").decode()\n",
    "    v=model_version\n",
    "    model_json={'m':pickled,'v':v}\n",
    "    \n",
    "    msg = json.dumps(model_json)\n",
    "    print(f'Model size : {sys.getsizeof(msg)}')\n",
    "    producer.produce(topic, value=msg, key=str(v))\n",
    "    producer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edead90-5dad-4993-b3fc-e47e1fb22f54",
   "metadata": {},
   "source": [
    "### Initialize metrics for training\n",
    "\n",
    "We initialize three metrics-\n",
    "1. ROCAUC\n",
    "2. F1\n",
    "3. MicroRecall\n",
    "\n",
    "This time we simply do multiple runs in sequence. In a typical scenario we would follow this process:\n",
    "1. Register metrics per run\n",
    "2. When executing a subsequent run, fetch the model artifact and metrics from the previous run\n",
    "3. Refine the previous run's model with the incremental dataset and refine the previous runs metrics\n",
    "4. Store the refined model artifact and the new metrics for the current run\n",
    "\n",
    "For simplicity, we simply keep the previous model version and metrics and for each run incrementall refine them and save it to the run artifacts in the experiment manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b5f6ee-d397-42c5-8572-da4b1496ec8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc = metrics.ROCAUC()\n",
    "f1 = metrics.F1()\n",
    "recall = metrics.MicroRecall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2ae2c-65a7-4bc1-bc65-e86ba11d743b",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Experiment Creation\n",
    "\n",
    "Create a new experiment or use the previously created one by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b128e87d-fa78-4668-b3d1-ca77419affde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
    "client = MlflowClient()\n",
    "EXPERIMENT_NAME = 'AdaptiveRandomForestExperiment-v1'\n",
    "model_name = EXPERIMENT_NAME\n",
    "exp = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "model_artifact = None\n",
    "if not exp:\n",
    "    EXPERIMENT_ID = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "    model_artifact = ensemble.AdaptiveRandomForestClassifier(leaf_prediction=\"mc\")\n",
    "else:\n",
    "    EXPERIMENT_ID = exp.experiment_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c624945b-20be-4aa5-9fdd-06b0750bbcea",
   "metadata": {},
   "source": [
    "###  Run Generation\n",
    "\n",
    "The method `generate_run(exp_id,index,model_artifact)` creates a run for the experiment created in the previous step. The run name is based on the following implementation:\n",
    "```\n",
    "s = now.strftime(\"%d-%m-%H-%M-%S\")\n",
    "run_name = f'run{s}-idx-{index}'\n",
    "```\n",
    "\n",
    "The method takes three parameters:\n",
    "1. `exp_id` - Experiment id in the MLflow\n",
    "2. `index` - This is a running number. We start with 0 and run 5 more runs which gives us indexes 0-6\n",
    "3. `model_artifact` - The model generated by the previous runs. Remember, this is online-learning where each version builds on its previous version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbfd2dd-da5d-47de-8c70-f6ae62b95a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_run(exp_id,index,model_artifact):\n",
    "    global auc\n",
    "    global f1\n",
    "    global recall\n",
    "    idx=0\n",
    "    now = datetime.now()\n",
    "    s = now.strftime(\"%d-%m-%H-%M-%S\")\n",
    "    run_name = f'run{s}-idx-{index}'\n",
    "    \n",
    "    with mlflow.start_run(experiment_id=exp_id, run_name=run_name) as run:\n",
    "        # Retrieve run id\n",
    "        RUN_ID = run.info.run_id\n",
    "        size=100 * (index+2)\n",
    "        max_train_size=100\n",
    "        max_size=200\n",
    "        \n",
    "        skip_size = size - max_size\n",
    "        dataset = datasets.MaliciousURL()\n",
    "        data = dataset.take(size)\n",
    "        cnt = 0\n",
    "        if skip_size == 0:\n",
    "            print(f'First Time Building Model')\n",
    "            for f, y in data:\n",
    "                cnt = cnt + 1\n",
    "                if (cnt<=max_train_size):\n",
    "                    model_artifact = model_artifact.learn_one(f,y)\n",
    "                else:\n",
    "                    score = model_artifact.predict_one(f)\n",
    "                    auc = auc.update(y,score)\n",
    "                    f1 = f1.update(y, score)\n",
    "                    recall = recall.update(y, score)\n",
    "        else:\n",
    "            cnt = 0\n",
    "            for f, y in data:\n",
    "                cnt = cnt + 1\n",
    "                if(cnt==skip_size):\n",
    "                    break\n",
    "            print(f'Skipped{skip_size}')\n",
    "            for f, y in data:\n",
    "                cnt = cnt + 1\n",
    "                if (cnt<=max_train_size):\n",
    "                    model_artifact = model_artifact.learn_one(f,y)\n",
    "                else:\n",
    "                    score = model_artifact.predict_one(f)\n",
    "                    auc = auc.update(y,score)\n",
    "                    f1 = f1.update(y, score)\n",
    "                    recall = recall.update(y, score)\n",
    "                \n",
    "\n",
    "            \n",
    "        # Track parameters\n",
    "        mlflow.log_param(\"leaf_prediction\", \"mc\")\n",
    "        mlflow.log_metric(\"ROCAUC\", auc.get())\n",
    "        mlflow.log_metric(\"f1\", auc.get())\n",
    "        mlflow.log_metric(\"recall\", auc.get())\n",
    "        \n",
    "        with open('/tmp/model.pkl', 'wb') as handle:\n",
    "            pickle.dump(model_artifact, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        mlflow.log_artifact('/tmp/model.pkl','models')\n",
    "        return run.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8188d1d3-e5ba-4397-b418-aff03ceee230",
   "metadata": {},
   "source": [
    "###  Get Latest Model Version\n",
    "\n",
    "MLflow supports the concept of `RegisteredModels` by name. Each registered models can have incrementing versions. Ths method below returns the latest version for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98f1720-6e07-4c8b-9754-735d4ff8acf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_latest_model_version_from_model_registry(registered_model):\n",
    "    versions = registered_model.latest_versions\n",
    "    current_version = None\n",
    "    if(len(versions)>1):\n",
    "        current_version = versions[1]\n",
    "    else:\n",
    "        current_version = versions[0]\n",
    "    return current_version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea1985-78ec-4fc8-85bf-f8b564dd8344",
   "metadata": {},
   "source": [
    "###  Generate the model version 1\n",
    "Execute a run and register the model. Push the model version to the kafka topic `model_updates` to which the model endpoint is listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba950d3-39af-4647-9787-e03ff7d125f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Time Building Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/05 23:49:13 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AdaptiveRandomForestExperiment-v1, version 6\n",
      "/tmp/ipykernel_1727/1433777571.py:2: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  local_path = client.download_artifacts(run_id, \"models/model.pkl\", '/tmp/')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size : 2634060\n"
     ]
    }
   ],
   "source": [
    "index=0\n",
    "#First time creating model\n",
    "model_artifact = ensemble.AdaptiveRandomForestClassifier(leaf_prediction=\"mc\")\n",
    "run = generate_run(EXPERIMENT_ID,index,model_artifact)\n",
    "\n",
    "registered_model = None\n",
    "try:\n",
    "    registered_model = client.get_registered_model(model_name)\n",
    "except:\n",
    "     client.create_registered_model(model_name)\n",
    "registered_model = client.get_registered_model(model_name)\n",
    "model_uri = \"runs:/{}/model\".format(run.run_id)\n",
    "result = client.create_model_version(\n",
    "    name=model_name,\n",
    "    source=model_uri,\n",
    "    run_id=run.run_id,\n",
    ") \n",
    "registered_model = client.get_registered_model(model_name)\n",
    "current_model_version = get_latest_model_version_from_model_registry(registered_model)\n",
    "publish_model_update_to_model_endpoint(run.run_id,current_model_version.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df0452-313f-4704-8477-2d3a9483610f",
   "metadata": {},
   "source": [
    "###  Generate the model version 2-6\n",
    "Execute a runs 2-6 and register each new model version\n",
    "Push the model versions to the kafka topic `model_updates` to which the model endpoint is listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d2bcd7-71b4-4ae4-9179-efd598586538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1727/1433777571.py:2: FutureWarning: ``mlflow.tracking.client.MlflowClient.download_artifacts`` is deprecated since 2.0. This method will be removed in a future release. Use ``mlflow.artifacts.download_artifacts`` instead.\n",
      "  local_path = client.download_artifacts(run_id, \"models/model.pkl\", '/tmp/')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/05 23:49:18 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AdaptiveRandomForestExperiment-v1, version 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size : 2634060\n",
      "Currently on iteration 2\n",
      "Skipped200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/05 23:49:22 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AdaptiveRandomForestExperiment-v1, version 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size : 2634060\n",
      "Currently on iteration 3\n",
      "Skipped300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/05 23:49:25 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AdaptiveRandomForestExperiment-v1, version 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size : 2634060\n",
      "Currently on iteration 4\n",
      "Skipped400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/05 23:49:29 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: AdaptiveRandomForestExperiment-v1, version 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size : 2634061\n"
     ]
    }
   ],
   "source": [
    "for index in range(1,5):\n",
    "    print(f'Currently on iteration {index}')\n",
    "    current_model_version = get_latest_model_version_from_model_registry(registered_model)\n",
    "    model_artifact = get_model_artifact(current_model_version.run_id)\n",
    "    run = generate_run(EXPERIMENT_ID,index,model_artifact)\n",
    "    registered_model = None\n",
    "    try:\n",
    "        registered_model = client.get_registered_model(model_name)\n",
    "    except:\n",
    "         client.create_registered_model(model_name)\n",
    "    model_uri = \"runs:/{}/model\".format(run.run_id)\n",
    "    result = client.create_model_version(\n",
    "        name=model_name,\n",
    "        source=model_uri,\n",
    "        run_id=run.run_id,\n",
    "    ) \n",
    "    registered_model = client.get_registered_model(model_name)\n",
    "    current_model_version = get_latest_model_version_from_model_registry(registered_model)\n",
    "    publish_model_update_to_model_endpoint(run.run_id,current_model_version.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f32a2-410d-4aee-9213-83f090cdf4a7",
   "metadata": {},
   "source": [
    "## Produce Features to the Features Kafka Topic\n",
    "\n",
    "Now use the `MaliciousURLModelProducer.ipynb` to publish features to the Kafka topic `features`. Monitor the topic `predictions` to determine if the model endpoint is processing the features and producing predictions using the latest model version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002a30b5-22f0-4a76-a191-608193485013",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test the model init and predict function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655141e-d97c-4e33-9e9b-1bfd3976cd5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "import os\n",
    "import model\n",
    "model.init()\n",
    "#model_test.init_get_latest_model()\n",
    "x = {\"2\": 1.0, \"4\": 0.0788382, \"5\": 0.131034, \"6\": 0.117647, \"10\": 1.0, \"11\": 0.142857, \"16\": 0.4, \"17\": 0.830283, \"18\": 0.83965, \"19\": 0.583194, \"20\": 1.0, \"21\": 0.285713, \"22\": 0.00595238, \"23\": 0.00595238, \"36\": 1.0, \"37\": 1.0, \"44\": 1.0, \"45\": 1.0, \"54\": 1.0, \"56\": 1.0, \"62\": 1.0, \"64\": 1.0, \"66\": 1.0, \"68\": 1.0, \"70\": 1.0, \"72\": 1.0, \"74\": 1.0, \"75\": 0.25, \"76\": 1.0, \"77\": 0.166667, \"79\": 0.0769231, \"81\": 0.05, \"82\": 1.0, \"84\": 1.0, \"86\": 1.0, \"88\": 1.0, \"90\": 1.0, \"92\": 1.0, \"94\": 1.0, \"96\": 1.0, \"102\": 1.0, \"104\": 1.0, \"106\": 1.0, \"108\": 1.0, \"110\": 1.0, \"112\": 1.0, \"131\": 1.0, \"133\": 1.0, \"139\": 1.0, \"141\": 1.0, \"143\": 1.0, \"145\": 1.0, \"147\": 1.0, \"149\": 1.0, \"253\": 1.0, \"260\": 1.0, \"277\": 1.0, \"304\": 1.0, \"305\": 1.0, \"425\": 1.0, \"521\": 1.0, \"673\": 1.0, \"674\": 1.0, \"675\": 1.0, \"676\": 1.0, \"731\": 1.0, \"732\": 1.0, \"733\": 1.0, \"1365\": 1.0, \"1488\": 1.0, \"2098\": 1.0, \"6027\": 1.0, \"6028\": 1.0, \"6029\": 1.0, \"6030\": 1.0, \"6031\": 1.0, \"9989\": 1.0, \"18073\": 1.0, \"18074\": 1.0, \"18077\": 1.0, \"18078\": 1.0, \"18079\": 1.0, \"18080\": 1.0, \"155153\": 1.0, \"155154\": 1.0, \"155155\": 1.0, \"155156\": 1.0, \"155157\": 1.0, \"155158\": 1.0, \"155159\": 1.0, \"155160\": 1.0, \"155161\": 1.0, \"155163\": 1.0, \"155164\": 1.0, \"155165\": 1.0, \"155166\": 1.0, \"155167\": 1.0, \"155168\": 1.0, \"155169\": 1.0, \"155170\": 1.0, \"155171\": 1.0, \"155172\": 1.0, \"155173\": 1.0, \"155174\": 1.0, \"155175\": 1.0, \"155176\": 1.0, \"155177\": 1.0, \"155178\": 1.0, \"155179\": 1.0, \"155180\": 1.0, \"155181\": 1.0, \"155182\": 1.0, \"155183\": 1.0, \"155184\": 1.0, \"155185\": 1.0, \"155186\": 1.0, \"155187\": 1.0, \"155188\": 1.0, \"155189\": 1.0, \"155190\": 1.0, \"155191\": 1.0, \"155192\": 1.0, \"155193\": 1.0, \"155194\": 1.0, \"155195\": 1.0, \"155196\": 1.0, \"155197\": 1.0, \"155198\": 1.0, \"155199\": 1.0, \"155200\": 1.0, \"155201\": 1.0, \"155202\": 1.0, \"155203\": 1.0, \"155204\": 1.0, \"155205\": 1.0, \"155206\": 1.0, \"155207\": 1.0, \"155208\": 1.0, \"155209\": 1.0, \"155210\": 1.0, \"155211\": 1.0, \"155212\": 1.0, \"155213\": 1.0, \"500481\": 1.0}\n",
    "model.predict(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d6aff-d716-4867-a037-5b43a5584441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
